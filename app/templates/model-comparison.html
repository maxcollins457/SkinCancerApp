{% extends "base-template.html" %}

{% block title %}Model Comparison{% endblock title %}

{% block main %}
<div class="container mt-4">
    <h1>Model Comparison</h1>
    <div class="d-flex justify-content-center mt-4">
        <ul class="nav nav-tabs" id="modelTabs" role="tablist">
            <li class="nav-item">
                <a class="nav-link active" id="model1-tab" data-toggle="tab" href="#model1" role="tab"
                    aria-controls="model1" aria-selected="true">Binary Classification</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" id="model2-tab" data-toggle="tab" href="#model2" role="tab" aria-controls="model2"
                    aria-selected="false">Traditional CNN</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" id="model3-tab" data-toggle="tab" href="#model3" role="tab" aria-controls="model3"
                    aria-selected="false">Multi-input</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" id="model4-tab" data-toggle="tab" href="#model4" role="tab" aria-controls="model4"
                    aria-selected="false">VGG-16</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" id="model5-tab" data-toggle="tab" href="#model5" role="tab" aria-controls="model5"
                    aria-selected="false">MobileNet</a>
            </li>
        </ul>
    </div>
    <div class="tab-content" id="modelTabsContent">
        <div class="tab-pane fade show active" id="model1" role="tabpanel" aria-labelledby="model1-tab">
            <div class="row mt-4">
                <div class="col">
                    <p>This model is a binary classification model. It predicts whether or not the lesion in the
                        uploaded image is cancerous or not.</p>
                    <h2>Model Structure</h2>
                    <p>The model utilizes a set of Conv2D layers with MaxPooling and Dropout layers. This architecture
                        is designed to effectively learn and represent features from the input images, enabling accurate
                        classification of skin lesions.</p>
                    <h3>Model Performance</h3>
                    <p>
                        The Confusion matrix for this architecture can be seen below. False negatives are minimised but
                        there is a 17% false positive rate.
                    </p>
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/bin_model_CM.png') }}"
                        alt="Confusion matrix for binary ML model">
                </div>
                <div class="col">
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/binary_model_plot.png') }}"
                        alt="Model Plot">
                </div>
            </div>
        </div>
        <div class="tab-pane fade" id="model2" role="tabpanel" aria-labelledby="model2-tab">
            <div class="row mt-4">
                <div class="col">
                    <h2>Model Structure</h2>
                    <p>The model utilizes a set of Conv2D layers with MaxPooling and Dropout layers. This architecture
                        is designed to effectively learn and represent features from the input images, enabling accurate
                        classification of skin lesions.</p>
                    <h3>Model Performance</h3>
                    <p>
                        The Confusion matrix for this architecture can be seen below.
                    </p>
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/model1_CM.png') }}"
                        alt="Confusion matrix for ML model">
                </div>

                <div class="col">
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/model_plot.png') }}"
                        alt="Model Plot">
                </div>
            </div>
        </div>

        <div class="tab-pane fade" id="model3" role="tabpanel" aria-labelledby="model3-tab">
            <div class="row mt-4">
                <div class="col">
                    <p>This model is a multi-input classification model. It predicts whether or not the lesion in the
                        uploaded image is cancerous or not. This is also given the age and sex of the patitent as well
                        as the localization of the lesion.</p>
                    <h2>Model Structure</h2>
                    <p>The model utilizes a set of Conv2D layers with MaxPooling and Dropout layers. This architecture
                        is designed to effectively learn and represent features from the input images, enabling accurate
                        classification of skin lesions. This also uses dense layers to extract information from the age,
                        sex and localization.</p>
                    <h3>Model Performance</h3>
                    <p>
                        The Confusion matrix for this architecture can be seen below.
                    </p>
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/multi_input_model_CM_balanced.png') }}"
                        alt="Confusion matrix for binary ML model">
                </div>
                <div class="col">
                    <img class="img-fluid"
                        src="{{ url_for('static', filename='img/models/multi_input_model_plot.png') }}" alt="Model Plot">
                </div>
            </div>
        </div>
        <div class="tab-pane fade" id="model4" role="tabpanel" aria-labelledby="model4-tab">
            <div class="row mt-4">
                <div class="col">
                    <p>This model based on the VGG-16 model developed by Oxford. VGG-16 is a convolutional neural
                        network
                        that is 16 layers deep. This has been trained on more than a
                        million images from the ImageNet database. The pretrained network can classify images into
                        1000 object categories.</p>
                    <p>Available from: <a href="https://www.robots.ox.ac.uk/~vgg/research/very_deep/"
                            target="_blank">VGG</a>.</p>
                    <h2>Model Structure</h2>
                    <p>Using Transfer Learning, this model takes the VGG model and adds a new output layer
                        to adapt it to this problem. Using VGG saves time in training as the model weights have already
                        been trained. These should perform the feature extraction.
                        Then by adding a new output layer, and training this, we can 'transfer' the
                        learning from the general image classifier to this specific problem.</p>
                    <h3>Model Performance</h3>
                    <p>
                        The Confusion matrix for this architecture can be seen below.
                    </p>
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/VGG_model_CM.png') }}"
                        alt="Confusion matrix for VGG based model">
                </div>
                <div class="col">
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/VGG_model_plot.png') }}"
                        alt="Model Plot">
                </div>
            </div>
        </div>
        <div class="tab-pane fade" id="model5" role="tabpanel" aria-labelledby="model5-tab">
            <div class="row mt-4">
                <div class="col">
                    <p>MobileNet is TensorFlow's first mobile computer vision model. It uses depthwise separable
                        convolutions to significantly reduce the number of parameters compared to other networks with
                        regular convolutions and the same depth in the nets. This results in lightweight deep neural
                        networks.</p>
                    <p>Available from: <a href="https://keras.io/api/applications/mobilenet/"
                            target="_blank">MobileNet</a>.</p>
                    <h2>Model Structure</h2>
                    <p>Using Transfer Learning, this model takes the MobileNet model and adds a new output layer
                        to adapt it to this problem. Using MobileNet saves time in training as the model weights have
                        already
                        been trained. These should perform the feature extraction.
                        Then by adding a new output layer, and training this, we can 'transfer' the
                        learning from the general image classifier to this specific problem.
                        This model also uses class weights in the training process. This helps with the imablanced
                        dataset. Class weights are used to assign different weights to different classes during
                        training. By giving higher weights to the minority class and lower weights to the majority
                        class, the model is encouraged to pay more attention to the minority class and make better
                        predictions for it. </p>
                    <h3>Model Performance</h3>
                    <p>
                        The Confusion matrix for this architecture can be seen below.
                    </p>
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/tripleFineTuneWeightedMobileNet_CM_perc.png') }}"
                        alt="Confusion matrix for MobileNet based model">
                </div>
                <div class="col">
                    <img class="img-fluid" src="{{ url_for('static', filename='img/models/VGG_model_plot.png') }}"
                        alt="Model Plot">
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock main %}